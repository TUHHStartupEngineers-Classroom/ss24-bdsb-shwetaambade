{
  "hash": "2d668b6b9f0b0834f384de9cb0be47da",
  "result": {
    "markdown": "---\ntitle: \"Data Acquisition\"\nauthor: \"Shweta Ambade\"\n---\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-1_024129b24e9df2a55125e02ccb3556e7'}\n\n```{.r .cell-code}\n#Challenge 1- API Challenge\n# Load packages\nlibrary(httr)\nlibrary(jsonlite)\n\n# API key for OpenWeatherMap\napi_key <- \"1b974d3ef182f3948d75d15456fbbd20\"\n\n# List of German cities\ngerman_cities <- c(\"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Frankfurt\", \"Stuttgart\", \"Düsseldorf\", \"Dortmund\", \"Essen\", \"Leipzig\")\n\n# Function to fetch weather data for a city\nfetch_weather <- function(city) {\n  # API endpoint\n  url <- paste0(\"https://api.openweathermap.org/data/2.5/weather?q=\", city, \"&appid=\", api_key)\n  \n  # Make GET request to API\n  response <- GET(url)\n  \n  # Check if request was successful\n  if (http_type(response) == \"application/json\") {\n    # Parse JSON response\n    weather_data <- content(response, \"text\", encoding = \"UTF-8\")\n    \n    # Convert JSON to list\n    weather_list <- fromJSON(weather_data)\n    \n    # Extract relevant information\n    if (\"main\" %in% names(weather_list) && \"weather\" %in% names(weather_list)) {\n      temperature <- weather_list$main$temp - 273.15  # Convert temperature from Kelvin to Celsius\n      humidity <- weather_list$main$humidity\n      weather_description <- weather_list$weather[1, \"description\"]\n      \n      # Create dataframe to store weather information\n      weather_df <- data.frame(\n        \"City\" = city,\n        \"Temperature (°C)\" = temperature,\n        \"Humidity (%)\" = humidity,\n        \"Description\" = weather_description\n      )\n      \n      return(weather_df)\n    } else {\n      cat(\"Failed to extract relevant information from the response for\", city, \"\\n\")\n      return(NULL)\n    }\n  } else {\n    cat(\"Failed to fetch weather data for\", city, \"\\n\")\n    return(NULL)\n  }\n}\n\n# Fetch weather data for each city\nweather_data_list <- lapply(german_cities, fetch_weather)\n\n# Combine weather data for all cities into a single dataframe\nweather_all <- do.call(rbind, weather_data_list)\n\n# Print weather dataframe\nprint(weather_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          City Temperature...C. Humidity....      Description\n#> 1      Berlin            20.66           67 scattered clouds\n#> 2     Hamburg            20.04           60 scattered clouds\n#> 3      Munich            20.12           54       few clouds\n#> 4     Cologne            19.29           68       few clouds\n#> 5   Frankfurt            18.16           78       light rain\n#> 6   Stuttgart            18.96           64       few clouds\n#> 7  Düsseldorf            18.40           80  overcast clouds\n#> 8    Dortmund            18.74           72    broken clouds\n#> 9       Essen            19.07           76    broken clouds\n#> 10    Leipzig            19.99           66       light rain\n```\n:::\n:::\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-2_983db171da2f5bdd6e70da3619082c20'}\n\n```{.r .cell-code}\n#Challenge 2- Web Scraping\n#Load necessary libraries\nlibrary(tidyverse) \nlibrary(rvest)     \nlibrary(xopen)     \nlibrary(jsonlite)  \nlibrary(glue)      \nlibrary(stringi)   \n\nurl_home <- \"https://www.rosebikes.de/fahrr%C3%A4der/mtb\"\n# Open links directly from RStudio to inspect them\n\nhtml_home <- read_html(url_home) # Read in the HTML for the entire web page\n\n# data scraping from the web page for  the bike models \n# Scrape the bike model names\nbike_model <- html_home %>%\n  html_nodes(css = \".basic-headline.basic-headline--no-margin.basic-headline--small.basic-headline--left\")%>%\n  html_text() %>%\n  str_remove_all(\"\\n\")\nbike_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  [1] \"PDQ            \"              \"COUNT SOLO            \"      \n#>  [3] \"THRILL HILL            \"      \"GROUND CONTROL            \"  \n#>  [5] \"ROOT MILLER            \"      \"BONERO            \"          \n#>  [7] \"SCRUB            \"            \"THE BRUCE            \"       \n#>  [9] \"ROOT MILLER PLUS            \" \"BONERO PLUS            \"\n```\n:::\n\n```{.r .cell-code}\n# data scraping from the web page for  the bike prices\nbike_price <- html_home %>%\n  html_nodes(css = \".catalog-category-bikes__price-title\") %>%\n  html_text() %>%\n  \n  str_remove_all(\"\\\\.\") %>%\n  stringr::str_replace_all(pattern = \"\\nab \", replacement = \"\") %>%\n  stringr::str_replace_all(pattern = \"\\n\", replacement = \"\") %>%\n  str_remove_all(\"€|ab|,|\\\\s\")\nbike_price\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  [1] \"269900\" \"49900\"  \"229900\" \"149900\" \"179900\" \"99900\"  \"329900\" \"79900\" \n#>  [9] \"399900\" \"449900\"\n```\n:::\n\n```{.r .cell-code}\n# merging the two tables into one\nda2 <- tibble(bike_model, bike_price)\n\n# Remove trailing zeros and convert to numeric\nda2$bike_price <- as.character(gsub(\"^0+\", \"\", da2$bike_price))\nda2$bike_price <- gsub(\"00$\", \"\", da2$bike_price)\n\n#d<-da2\nda2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"bike_model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"bike_price\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"PDQ\",\"2\":\"2699\"},{\"1\":\"COUNT SOLO\",\"2\":\"499\"},{\"1\":\"THRILL HILL\",\"2\":\"2299\"},{\"1\":\"GROUND CONTROL\",\"2\":\"1499\"},{\"1\":\"ROOT MILLER\",\"2\":\"1799\"},{\"1\":\"BONERO\",\"2\":\"999\"},{\"1\":\"SCRUB\",\"2\":\"3299\"},{\"1\":\"THE BRUCE\",\"2\":\"799\"},{\"1\":\"ROOT MILLER PLUS\",\"2\":\"3999\"},{\"1\":\"BONERO PLUS\",\"2\":\"4499\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nwrite_rds(da2, \"C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/DataAcquistion2.R\")\nwrite.csv(x=da2, file=\"C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/DataAcquistion2.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}