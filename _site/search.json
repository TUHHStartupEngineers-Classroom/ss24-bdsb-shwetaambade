[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "1 Load required packages\nlibrary(data.table)\n\n\n2 Set working directory if needed\n\n\n3 setwd(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/Patent_data_reduced/Patent_data_reduced/”)\n\n\n4 Load data\nassignee &lt;- fread(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/Patent_data_reduced/Patent_data_reduced/assignee.tsv”) patent_assignee &lt;- fread(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/Patent_data_reduced/Patent_data_reduced/patent_assignee.tsv”) patent &lt;- fread(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/Patent_data_reduced/Patent_data_reduced/patent.tsv”) uspc &lt;- fread(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/Patent_data_reduced/Patent_data_reduced/uspc.tsv”)\n\n\n5 Check column names\ncolnames(assignee) colnames(patent_assignee) colnames(patent) colnames(uspc)\n\n\n6 Question 1: Patent Dominance- correct\n\n\n7 Join assignee and patent_assignee tables, filter for US companies, then count patents by company\ndominance &lt;- assignee[patent_assignee, on = c(“id” = “assignee_id”)][type %in% c(2, 4, 6, 8, 9), .N, by = organization][order(-N)]\n\n\n8 Display top 10 US companies with the most assigned/granted patents\nhead(dominance, 10)\n\n\n9 Question 2: Recent Patent Activity-correct\n\n\n10 Filter patents granted in August 2014, then count patents by company\nrecent_activity &lt;- assignee[patent_assignee[patent, on = c(“patent_id” = “id”)][date &gt;= “2014-08-01” & date &lt;= “2014-08-31”], on = c(“id” = “assignee_id”)][type %in% c(2, 4, 6, 8, 9), .N, by = organization][order(-N)]\n\n\n11 Display top 10 US companies with the most new granted patents for August 2014\nhead(recent_activity, 10)\n\n\n12 Question 3: Innovation in Tech-correct\n\n\n13 Join assignee, patent_assignee, and uspc tables, then count patents by tech sector\ninnovation &lt;- assignee[patent_assignee, on = c(“id” = “assignee_id”)][uspc, on = c(“patent_id” = “patent_id”)][, .N, by = .(organization, mainclass_id)][order(-N)]\n\n\n14 Display the top 10 most innovative tech sectors\ntop_sectors &lt;- head(innovation, 10) print(top_sectors)\n\n\n15 Count the number of patents per main class\nmain_class_counts &lt;- innovation[, .N, by = mainclass_id]\n\n\n16 Sort the main classes by patent count\nsorted_main_classes &lt;- main_class_counts[order(-N)]\n\n\n17 Display the top 5 USPTO tech main classes\ntop_main_classes &lt;- head(sorted_main_classes, 5) print(top_main_classes)"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "1 Load necessary libraries\nlibrary(dplyr) library(ggplot2) library(tidyr) library(stringr)\n\n\n2 Read data from Excel files\nbikes &lt;- read_excel(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/ds_data/ds_data/01_bike_sales/01_raw_data/bikes.xlsx”) bikeshops &lt;- read_excel(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/ds_data/ds_data/01_bike_sales/01_raw_data/bikeshops.xlsx”) orderlines &lt;- read_excel(“C:/Users/Shweta/Documents/GitHub/ss24-bdsb-shwetaambade/datascience/ds_data/ds_data/01_bike_sales/01_raw_data/orderlines.xlsx”)\n\n\n3 Merge dataframes\nbike_orderlines_joined &lt;- orderlines %&gt;% left_join(bikes, by = c(“product.id” = “bike.id”)) %&gt;% left_join(bikeshops, by = c(“customer.id” = “bikeshop.id”))\n\n\n4 Extract state abbreviation from location\nbike_orderlines_wrangled &lt;- bike_orderlines_joined %&gt;% separate(location, into = c(“city”, “state”), sep = “,”) %&gt;% mutate(state = str_trim(state))\n\n\n5 Calculating total price\nbike_orderlines_wrangled &lt;- bike_orderlines_wrangled %&gt;% mutate(total_price = price * quantity)\n\n\n6 Group by state and summarize sales\nsales_by_state_tbl &lt;- bike_orderlines_wrangled %&gt;% group_by(state, city) %&gt;% summarise(total_sales = sum(total_price)) %&gt;% arrange(desc(total_sales)) # Arrange states by total sales, descending order\n\n\n7 Visualize sales by state\nsales_by_state_tbl %&gt;% ggplot(aes(x = reorder(state, -total_sales), y = total_sales)) + geom_bar(stat = “identity”, fill = “#2DC6D6”) + labs( title = “Revenue by State”, x = “State”, y = “Revenue” ) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "#API Challenge #load packages library\nlibrary(RSQLite) library(httr) library(jsonlite)\n\n1 API key for OpenWeatherMap\napi_key &lt;- “1b974d3ef182f3948d75d15456fbbd20”\n\n\n2 City for which you want to fetch weather data\ncity &lt;- URLencode(“Berlin”)\n\n\n3 API endpoint\nurl &lt;- paste0(“https://api.openweathermap.org/data/2.5/weather?q=”, city, “&appid=”, api_key)\n\n\n4 Make GET request to API\nresponse &lt;- GET(url)\n\n\n5 Check if request was successful\nif (http_type(response) == “application/json”) { # Parse JSON response weather_data &lt;- fromJSON(content(response, “text”))\n# Extract relevant information temperature &lt;- weather_data\\(main\\)temp - 273.15 # Convert temperature from Kelvin to Celsius humidity &lt;- weather_data\\(main\\)humidity\n# Create dataframe to store weather information weather_df &lt;- data.frame( “City” = city, “Temperature (°C)” = temperature, “Humidity (%)” = humidity, “Description” = weather_description )\n# Print weather dataframe print(weather_df)\n# If you want to save the dataframe to a table in a database, you can use RSQLite or any other database package\n} else { cat(“Failed to fetch weather data.”) }\n#Web Scraping # Load required libraries #Web Scraping # Load required libraries library(rvest)\n\n\n6 URL of the website to scrape\nurl &lt;- “https://www.radon-bikes.de”\n\n\n7 Read the HTML content of the website\npage &lt;- read_html(url)\n\n\n8 Extract model names and prices\nmodel_names &lt;- page %&gt;% html_nodes(“.product-name a”) %&gt;% html_text()\nprices &lt;- page %&gt;% html_nodes(“.price”) %&gt;% html_text()\n\n\n9 Clean up the data\nprices &lt;- gsub(“[^0-9.,]”, ““, prices) # Remove non-numeric characters prices &lt;- as.numeric(gsub(”,“,”.”, prices)) # Convert to numeric format\n\n\n10 Create a data frame\nscraped_data &lt;- data.frame(Model_Name = model_names, Price = prices)\n\n\n11 Print the first 10 rows of the scraped data\nprint(head(scraped_data, 10))"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "#challenge1 - correct library(readr) library(tidyverse)\n\n1 Read COVID-19 data\ncovid_data_tbl &lt;- read_csv(“https://covid.ourworldindata.org/data/owid-covid-data.csv”)\n\n\n2 Filter data for specified regions\nspecified_regions &lt;- c(“Europe”, “France”, “Germany”, “Spain”, “United Kingdom”, “United States”) filtered_data &lt;- covid_data_tbl %&gt;% filter(location %in% specified_regions & !is.na(total_cases))\n\n\n3 Plot cumulative COVID-19 cases over time for each region\nfiltered_data %&gt;% ggplot(aes(date, total_cases, color = location)) + geom_line() + scale_color_manual(values = c(Europe = “#E41A1C”, France = “#377EB8”, Germany = “#4DAF4A”, Spain = “#FF7F00”, United Kingdom = “#984EA3”, United States = “#FFFF33”)) + labs(title = “Cumulative COVID-19 Cases Over Time”, x = “Date”, y = “Total Cases”, color = “Region”) + theme_minimal()\n#challenge2 library(dplyr) library(readr)\n\n\n4 Load the COVID-19 data\ncovid_data_tbl &lt;- read_csv(“https://covid.ourworldindata.org/data/owid-covid-data.csv”)\n\n\n5 Filter the data to include only necessary columns and rows\ncovid_data_filtered &lt;- covid_data_tbl %&gt;% filter(!is.na(population)) %&gt;% group_by(location) %&gt;% summarize(total_deaths = max(total_deaths, na.rm = TRUE), total_cases = max(total_cases, na.rm = TRUE), population = max(population, na.rm = TRUE)) %&gt;% mutate(mortality_rate = total_deaths / population, case_fatality_rate = total_deaths / total_cases) %&gt;% filter(!is.na(mortality_rate)) # or !is.na(case_fatality_rate) if plotting case-fatality rate\nlibrary(ggplot2) library(maps)\n\n\n6 Load world map data\nworld &lt;- map_data(“world”)\n\n\n7 Merge data with world map data\nmerged_data &lt;- merge(world, covid_data_filtered, by.x = “region”, by.y = “location”, all.x = TRUE)\n\n\n8 Plot the map with adjusted settings\nggplot() + geom_map(data = merged_data, map = merged_data, aes(map_id = region, fill = mortality_rate), # or fill = case_fatality_rate if plotting case-fatality rate color = “black”) + scale_fill_gradient(name = “Mortality Rate”, low = “lightblue”, high = “darkred”, na.value = “grey”) + # or “Case-Fatality Rate” if plotting case-fatality rate theme_minimal() + coord_map(“mercator”) + # Adjust map projection labs(title = “World Mortality Rate Distribution”) # or “World Case-Fatality Rate Distribution” if plotting case-fatality rate"
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  }
]